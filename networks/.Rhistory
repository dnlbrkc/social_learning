biasVariance4
biasVariance4
str(biasVariance4)
str(biasVariance4$variable)
biasVariance4$variable
biasVariance4$variable <-
)
rep("biasIrError","variance",each=8)
rep(c("biasIrError","variance"),each=8)
rep(c("biasIrError","variance"),times=8)
biasVariance4$variable <- factor(biasVariance4$variable,levels=rep(c("biasIrError","variance"),times=8))
biasVariance4$variable <- factor(biasVariance4$variable,levels=c(rep(c("biasIrError","variance"),times=8)))
biasVariance4$variable <- factor(biasVariance4$variable,levels=c("biasIrError","variance"))
biasVariance4
biasVariance4$variable
ggplot(data=biasVariance4, aes(x=strategy, y=mean, fill=variable, order=desc(variable))) + geom_bar(stat = "summary",fun.y = "mean") + scale_x_discrete("Strategies",labels=c("RN","WTC","PC","SC","BF","II","CB","WC")) + scale_y_continuous("Error") +  scale_fill_discrete("Type of error", labels=c("Variance", "Bias + Ir. error")) + ggtitle("Aggregate results")
ggplot(data=biasVariance4, aes(x=strategy, y=mean, fill=variable, order=desc(variable))) + geom_bar(stat = "summary",fun.y = "mean") + scale_x_discrete("Strategies",labels=c("RN","WTC","PC","SC","BF","II","CB","WC")) + scale_y_continuous("Error") +  scale_fill_discrete("Type of error", labels=c( "Bias + Ir. error","Variance")) + ggtitle("Aggregate results")
biasVariance4
p1 <- ggplot(data=biasVariance4, aes(x=strategy, y=mean, fill=variable, order=desc(variable))) + geom_bar(stat = "summary",fun.y = "mean") + scale_x_discrete("Strategies",labels=c("RN","WTC","PC","SC","BF","II","CB","WC")) + scale_y_continuous("Error") +  scale_fill_discrete("Type of error", labels=c( "Bias + Ir. error","Variance")) + ggtitle("Aggregate results")
save_plot("~/Desktop/biasVariance.pdf", p1,
base_aspect_ratio = 2 # make room for figure legend
)
save_plot("~/Desktop/biasVariance.pdf", p1,
base_aspect_ratio = 1 # make room for figure legend
)
save_plot("~/Desktop/biasVariance.pdf", p1,
base_aspect_ratio = 1.5 # make room for figure legend
)
?split
a <- rep(c(1,2),each=5)
a
b <- rep(c(1:5),each=2)
b
c <- cbind(a,b)
split(c,c[,2])
c
c <- as.data.frame(c)
split(c,c$b)
?subset
subset(c,c$b==2)
?aggregate
aggregate(c,2,mean)
aggregate(c,c$b,mean)
aggregate(c,list(c$b),mean)
c
library(dplyr)
data(mtcars)
str()
ls()
str(mtcars)
select(mtcars,mpg,gear)
str(mtcars)
select(mtcars,am:carb)
filter(mtcars,mpg>10)
filter(mtcars,mpg!=NA)
filter(mtcars,mtcars!=NA)
filter(mtcars,mtcars)
filter(mtcars,mpg!=NA)
filter(mtcars,mpg==NA)
filter(mtcars,mpg:gears!=NA)
filter(mtcars,mpg:gear!=NA)
mtcars %>% filter(mpg>10) %>% mean
mtcars %>% filter(mpg>10) %>% mean()
mtcars %>% filter(mpg>10) %>% head()
mtcars %>% filter(mpg>10) %>% colMeans()
?arrange
mtcars %>% filter(mpg>10) %>% head()
head(mtcars %>% filter(mpg>10))
?n
n(mtcars)
summarise(mtcars,n())
nrow(mtcars)
summarise(mtcars,n=n())
head(mtcars)
mtcars %>% head()
mtcars %>% group_by(cyl)
mtcars %>% select(cyl)
mtcars %>% group_by(cyl)
mtcars %>% select(cyl) %>% unique()
mtcars %>% group_by(cyl) %>% colMeans()
mtcars %>% group_by(cyl) %>% rowMeans()
?group_by
mtcars %>% group_by(cyl) %>% table()
mtcars %>% group_by(cyl)
mtcars %>% group_by(am)
mtcars %>% group_by(am) %>% mean()
mtcars %>% group_by(am) %>% summarise(meanmpg = mean(mpg))
mtcars %>% group_by(mpg) %>% summarise(meanmpg = mean(mpg))
mtcars %>% group_by(cyl) %>% summarise(meanmpg = mean(mpg))
library(rprojroot)
rprojroot::find_root_file
?find_root_file
sample(bin_neighbors[[neigh]][,agents[[i]][n,1]+1],1)
load("landscapes/bin_neighbors2.Rdata")
setwd("~/GitHub/social_learning/")
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
sample(1:15,1)
bin_neighs <- function(x, nf, n) {
bitwXor(x, colSums(combn(2^(0:(n-1)), nf)))
}
r <- as.integer( commandArgs(TRUE)[1])
N=15
bin_neighbors <- list()
for(i in 1:2){
bin_neighbors[[i]] <-sapply(0:(2^N-1), function(x) bin_neighs(x, i, N))
}
save(bin_neighbors,file="~/Desktop/bin_neighbors.Rdata")
rm(list=ls())
library(gtools)
library(fGarch)
networks <- c("lattice.Rdata",
"max-max-betweenness.Rdata",
"max-mean-betweenness.Rdata",
"max-mean-clustering.Rdata",
"max-var-constraint.Rdata",
"fully-connected.Rdata",
"max-max-closeness.Rdata",
"min-max-closeness.Rdata",
"min-mean-betweenness.Rdata",
"min-mean-clustering.Rdata")
source("landscapes/generate_NK.R")
load("~/Desktop/bin_neighbors.Rdata")
n.strat=6 #NO. STRATEGIES
N=15; K=7 #NK PARAMETERS
n.agents=100 #NO. AGENTS
tsteps=200 #NO. TIME STEPS
#REPLICATION ID
r <- as.integer( commandArgs(TRUE)[1])
#STORE RESULTS
diversity<-matrix(NA,ncol=6,nrow=tsteps)
perf.time<-matrix(NA,ncol=6,nrow=tsteps)
#GENERATE LANDSCAPE
LS<-permutations(2,N,v=c(0,1),repeats.allowed=TRUE)
LS<-as.data.frame(LS)
if (K==0){
depends <- as.vector(1:N)
values <- replicate(N,round(runif(2,0,1),1))
fitness <- values
} else {
depends <- rbind(1:N,replicate(N,sample(c(1:N),K,replace=F)))
combinations <- permutations(2,K+1,v=c(0,1),repeats.allowed=TRUE)
values <- replicate(N,round(runif(nrow(combinations),0,1),1))
fitness <- cbind(combinations,values)
}
landscape <- generate_landscape(N,K,LS,fitness,depends)
landscape[,N+1] <- (landscape[,N+1]/max(landscape[,N+1]))^8
landscape <- cbind(0:(nrow(landscape)-1),landscape[,N+1])
net <- networks
setwd("networks/")
load(net)
contacts <- network
#AVERAGE OVER 100 LANDSCAPES
total.perftime <- matrix(0,ncol=n.strat,nrow=tsteps)
total.diversity <- matrix(0,ncol=n.strat,nrow=tsteps)
reps = 1
net <- networks[1]
setwd("networks/")
load(net)
contacts <- network
#AVERAGE OVER 100 LANDSCAPES
total.perftime <- matrix(0,ncol=n.strat,nrow=tsteps)
total.diversity <- matrix(0,ncol=n.strat,nrow=tsteps)
reps = 1
#FOR EACH STRATEGY
for (s in c(1:6)){
#DETERMINE SAMPLE SIZE
if (s == 1 || s == 3) samplesize<-3 else if (s == 2 || s == 4) samplesize<-9 else samplesize<-1
agents<-list()
#ALLOCATE RANDOM STARTING POSITIONS
agents[[1]] <- landscape[sample(1:2^N,100,replace=F),]
#FOR EACH TIME STEP
for (i in 2:tsteps){
#CARRY OVER OPTION FROM PREVIOUS TIME STEP
agents[[i]] <- agents[[i-1]]
#SAMPLE 's' OTHER PEOPLE
#samples <- replicate(n.agents,sample(1:n.agents,samplesize,replace=F))
samples <- sapply(1:100, function(x) sample(contacts[contacts[,1]==x,2],samplesize))
if (s == 1 || s == 2 ){ #IMPLEMENT BEST MEMBER STRATEGY
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents){
payoffs <- agents[[i]][samples[,j],2] #look up payoffs of samples
best<-which(payoffs==max(payoffs)) #select highest payoff
if(length(best)>1) best <- sample(best,1) #if there's a tie in highest payoff, sample randomly
agents2[j,] <- agents[[i]][samples[best,j],] #adopt choice of best member
if(agents2[j,2]<=agents[[i-1]][j,2]){ #if payoff worse or equal, learn individually
ind.learn[j] <- j
}
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else if (s == 3 || s == 4 ) { #IMPLEMENT CONFORMITY STRATEGY
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents){
a<-agents[[i]][samples[,j],1]
b<-tabulate(a)
freq <- b[b==max(b)]
if(length(freq)>1 & length(freq)<samplesize){
CH<-sample(which(b==freq[1]),1)
} else if (length(freq)==samplesize) {
ind.learn[j]<-j #if all options equally frequent, learn individually
} else {
CH <- which(b==freq[1])
}
if(length(freq)!=samplesize){
agents2[j,1] <- CH
agents2[j,2] <- landscape[(CH+1),2]
}
if(agents2[j,2]<=agents[[i-1]][j,2]){
ind.learn[j]<-j
}
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else if (s==5) { #IMPLEMENT RANDOM COPYING
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents) {
agents2[j,] <- agents[[i]][samples[j],]
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else { # NO SOCIAL LEARNING CONDITION
agents[[i]]<-agents[[i-1]]
ind.learn<-1:100
}
#IMPLEMENT INDIVIDUAL LEARNING
if(length(ind.learn)>=1){
h=0
choose<-vector()
for (n in c(ind.learn)){
neigh <- sample(1:15,1)
h=h+1
choose[h] <- sample(bin_neighbors[[neigh]][,agents[[i]][n,1]+1],1)
}
choose1 <- choose+1
pay<-sapply(1:length(choose1), function(x) landscape[choose1[x],2])
new<-cbind(choose,pay)
l=0
for (n in c(ind.learn)){
l=l+1
agents[[i]][n,] <- new[l,]
}
}
#COMPARE PAYOFFS AFTER LEARNING AND DECIDE WHETHER OR NOT TO SWITCH
switching <- ifelse(agents[[i-1]][,2] < agents[[i]][,2],1,0)*1:n.agents
not.switching <- setdiff(1:100,switching[switching!=0])
agents[[i]][not.switching,] <- agents[[i-1]][not.switching,]
}
perf.time[,s] <- sapply(1:tsteps, function(x) mean(agents[[x]][,2]))
diversity[,s] <- sapply(1:tsteps, function(x) nrow(unique(agents[[x]])))
}
sample(1:2,1)
sample(1:2,1)
sample(1:2,1)
sample(1:2,1)
sample(1:2,1)
sample(1:2,1)
sample(1:2,1)
#FOR EACH STRATEGY
for (s in c(1:6)){
#DETERMINE SAMPLE SIZE
if (s == 1 || s == 3) samplesize<-3 else if (s == 2 || s == 4) samplesize<-9 else samplesize<-1
agents<-list()
#ALLOCATE RANDOM STARTING POSITIONS
agents[[1]] <- landscape[sample(1:2^N,100,replace=F),]
#FOR EACH TIME STEP
for (i in 2:tsteps){
#CARRY OVER OPTION FROM PREVIOUS TIME STEP
agents[[i]] <- agents[[i-1]]
#SAMPLE 's' OTHER PEOPLE
#samples <- replicate(n.agents,sample(1:n.agents,samplesize,replace=F))
samples <- sapply(1:100, function(x) sample(contacts[contacts[,1]==x,2],samplesize))
if (s == 1 || s == 2 ){ #IMPLEMENT BEST MEMBER STRATEGY
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents){
payoffs <- agents[[i]][samples[,j],2] #look up payoffs of samples
best<-which(payoffs==max(payoffs)) #select highest payoff
if(length(best)>1) best <- sample(best,1) #if there's a tie in highest payoff, sample randomly
agents2[j,] <- agents[[i]][samples[best,j],] #adopt choice of best member
if(agents2[j,2]<=agents[[i-1]][j,2]){ #if payoff worse or equal, learn individually
ind.learn[j] <- j
}
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else if (s == 3 || s == 4 ) { #IMPLEMENT CONFORMITY STRATEGY
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents){
a<-agents[[i]][samples[,j],1]
b<-tabulate(a)
freq <- b[b==max(b)]
if(length(freq)>1 & length(freq)<samplesize){
CH<-sample(which(b==freq[1]),1)
} else if (length(freq)==samplesize) {
ind.learn[j]<-j #if all options equally frequent, learn individually
} else {
CH <- which(b==freq[1])
}
if(length(freq)!=samplesize){
agents2[j,1] <- CH
agents2[j,2] <- landscape[(CH+1),2]
}
if(agents2[j,2]<=agents[[i-1]][j,2]){
ind.learn[j]<-j
}
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else if (s==5) { #IMPLEMENT RANDOM COPYING
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents) {
agents2[j,] <- agents[[i]][samples[j],]
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else { # NO SOCIAL LEARNING CONDITION
agents[[i]]<-agents[[i-1]]
ind.learn<-1:100
}
#IMPLEMENT INDIVIDUAL LEARNING
if(length(ind.learn)>=1){
h=0
choose<-vector()
for (n in c(ind.learn)){
neigh <- sample(1:2,1)
h=h+1
choose[h] <- sample(bin_neighbors[[neigh]][,agents[[i]][n,1]+1],1)
}
choose1 <- choose+1
pay<-sapply(1:length(choose1), function(x) landscape[choose1[x],2])
new<-cbind(choose,pay)
l=0
for (n in c(ind.learn)){
l=l+1
agents[[i]][n,] <- new[l,]
}
}
#COMPARE PAYOFFS AFTER LEARNING AND DECIDE WHETHER OR NOT TO SWITCH
switching <- ifelse(agents[[i-1]][,2] < agents[[i]][,2],1,0)*1:n.agents
not.switching <- setdiff(1:100,switching[switching!=0])
agents[[i]][not.switching,] <- agents[[i-1]][not.switching,]
}
perf.time[,s] <- sapply(1:tsteps, function(x) mean(agents[[x]][,2]))
diversity[,s] <- sapply(1:tsteps, function(x) nrow(unique(agents[[x]])))
}
#FOR EACH STRATEGY
for (s in c(1:6)){
#DETERMINE SAMPLE SIZE
if (s == 1 || s == 3) samplesize<-3 else if (s == 2 || s == 4) samplesize<-9 else samplesize<-1
agents<-list()
#ALLOCATE RANDOM STARTING POSITIONS
agents[[1]] <- landscape[sample(1:2^N,100,replace=F),]
#FOR EACH TIME STEP
for (i in 2:tsteps){
#CARRY OVER OPTION FROM PREVIOUS TIME STEP
agents[[i]] <- agents[[i-1]]
#SAMPLE 's' OTHER PEOPLE
#samples <- replicate(n.agents,sample(1:n.agents,samplesize,replace=F))
samples <- sapply(1:100, function(x) sample(contacts[contacts[,1]==x,2],samplesize))
if (s == 1 || s == 2 ){ #IMPLEMENT BEST MEMBER STRATEGY
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents){
payoffs <- agents[[i]][samples[,j],2] #look up payoffs of samples
best<-which(payoffs==max(payoffs)) #select highest payoff
if(length(best)>1) best <- sample(best,1) #if there's a tie in highest payoff, sample randomly
agents2[j,] <- agents[[i]][samples[best,j],] #adopt choice of best member
if(agents2[j,2]<=agents[[i-1]][j,2]){ #if payoff worse or equal, learn individually
ind.learn[j] <- j
}
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else if (s == 3 || s == 4 ) { #IMPLEMENT CONFORMITY STRATEGY
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents){
a<-agents[[i]][samples[,j],1]
b<-tabulate(a)
freq <- b[b==max(b)]
if(length(freq)>1 & length(freq)<samplesize){
CH<-sample(which(b==freq[1]),1)
} else if (length(freq)==samplesize) {
ind.learn[j]<-j #if all options equally frequent, learn individually
} else {
CH <- which(b==freq[1])
}
if(length(freq)!=samplesize){
agents2[j,1] <- CH
agents2[j,2] <- landscape[(CH+1),2]
}
if(agents2[j,2]<=agents[[i-1]][j,2]){
ind.learn[j]<-j
}
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else if (s==5) { #IMPLEMENT RANDOM COPYING
ind.learn<-vector(length=n.agents)
agents2 <- agents[[i]]
for (j in 1:n.agents) {
agents2[j,] <- agents[[i]][samples[j],]
}
ind.learn<-ind.learn[ind.learn!=0]
#those who do not learn individually adopt the socially acquired option
no.learn <- setdiff(1:100,ind.learn)
if(length(no.learn)>0){
agents[[i]][no.learn,] <- agents2[no.learn,]
}
} else { # NO SOCIAL LEARNING CONDITION
agents[[i]]<-agents[[i-1]]
ind.learn<-1:100
}
#IMPLEMENT INDIVIDUAL LEARNING
if(length(ind.learn)>=1){
h=0
choose<-vector()
for (n in c(ind.learn)){
neigh <- sample(1:2,1)
h=h+1
choose[h] <- sample(bin_neighbors[[neigh]][,agents[[i]][n,1]+1],1)
}
choose1 <- choose+1
pay<-sapply(1:length(choose1), function(x) landscape[choose1[x],2])
new<-cbind(choose,pay)
l=0
for (n in c(ind.learn)){
l=l+1
agents[[i]][n,] <- new[l,]
}
}
#COMPARE PAYOFFS AFTER LEARNING AND DECIDE WHETHER OR NOT TO SWITCH
switching <- ifelse(agents[[i-1]][,2] < agents[[i]][,2],1,0)*1:n.agents
not.switching <- setdiff(1:100,switching[switching!=0])
agents[[i]][not.switching,] <- agents[[i-1]][not.switching,]
}
perf.time[,s] <- sapply(1:tsteps, function(x) mean(agents[[x]][,2]))
diversity[,s] <- sapply(1:tsteps, function(x) nrow(unique(agents[[x]])))
}
bin_neighs <- function(x, nf, n) {
bitwXor(x, colSums(combn(2^(0:(n-1)), nf)))
}
r <- as.integer( commandArgs(TRUE)[1])
N=6
bin_neighbors <- list()
for(i in 1:15){
bin_neighbors[[i]] <-sapply(0:(2^N-1), function(x) bin_neighs(x, i, N))
}
save(bin_neighbors,file="~/Desktop/bin_neighbors.Rdata")
bin_neighs <- function(x, nf, n) {
bitwXor(x, colSums(combn(2^(0:(n-1)), nf)))
}
r <- as.integer( commandArgs(TRUE)[1])
N=15
bin_neighbors <- list()
for(i in 1:15){
bin_neighbors[[i]] <-sapply(0:(2^N-1), function(x) bin_neighs(x, i, N))
}
